CREATE TABLE v64_deye_dw_ods.ods_nf_flux(
  data_type     Integer,
  user_group    String,
  user_name     String,
  strsrc_ip     String,
  strdst_ip     String,
  ip_type       Integer,
  up_flux       Bigint,
  down_flux     Bigint,
  dev_id        String,
  terminal_type String,
  app_type      String,
  app_name      String,
  is_webapp     Integer,
  ntime         Integer,
  site          String,
  line_id       String,
  capture_time  Bigint,
  insert_time   Bigint,
  data_id       String,
  uparea_id     Integer,
  insert_day    String,
  insert_hour   String,
  insert_min    String
)WITH (
    'type' = 'hive',
    'catalog' = 'default',
    'database' = 'v64_deye_dw_ods',
    'config.directory' = '/usr/hdp/current/hive-client/conf/',
    'version' = '3.1.0',
    'createTable' = 'false',
    'jdbc.url' = 'jdbc:hive2://172.16.80.12:10000',
    'yarn-site.xml' = '/usr/hdp/current/hadoop-client/conf/yarn-site.xml',
    'core-site.xml' = '/usr/hdp/current/hadoop-client/conf/core-site.xml',
    'hdfs-site.xml' = '/usr/hdp/current/hadoop-client/conf/hdfs-site.xml',
    'url' = '172.16.80.12:10000',
    'security.mode.flag' = 'false',
    'partitioned' = 'insert_day String,insert_hour String,insert_min String',
    'streaming-source.enable' = 'false',
    'table.exec.hive.infer-source-parallelism.max' = '128'
    );

CREATE TABLE v64_deye_dw_ods.ods_nf_flux_store(
  data_type     Integer,
  user_group    String,
  user_name     String,
  strsrc_ip     String,
  strdst_ip     String,
  ip_type       Integer,
  up_flux       Bigint,
  down_flux     Bigint,
  dev_id        String,
  terminal_type String,
  app_type      String,
  app_name      String,
  is_webapp     Integer,
  ntime         Integer,
  site          String,
  line_id       String,
  capture_time  Bigint,
  insert_time   Bigint,
  data_id       String,
  uparea_id     Integer,
  capture_day   String,
  capture_hour  String
)WITH (
     'type' = 'hive',
     'catalog' = 'default',
     'database' = 'v64_deye_dw_ods',
     'config.directory' = '/usr/hdp/current/hive-client/conf/',
     'version' = '3.1.0',
     'createTable' = 'false',
     'jdbc.url' = 'jdbc:hive2://172.16.80.12:10000',
     'yarn-site.xml' = '/usr/hdp/current/hadoop-client/conf/yarn-site.xml',
     'core-site.xml' = '/usr/hdp/current/hadoop-client/conf/core-site.xml',
     'hdfs-site.xml' = '/usr/hdp/current/hadoop-client/conf/hdfs-site.xml',
     'url' = '172.16.80.12:10000',
     'security.mode.flag' = 'false',
     'partitioned' = 'capture_day String,capture_hour String',
     'sink.partition-commit.delay' = '1 min',
     'sink.partition-commit.policy.kind' = 'metastore,success-file',
     'partition.time-extractor.timestamp-pattern' = '$capture_day $capture_hour:00:00'
     );

insert into v64_deye_dw_ods.ods_nf_flux_store
select
  data_type,
  user_group,
  user_name,
  strsrc_ip,
  strdst_ip,
  ip_type,
  up_flux,
  down_flux,
  dev_id,
  terminal_type,
  app_type,
  app_name,
  is_webapp,
  ntime,
  site,
  line_id,
  capture_time,
  insert_time,
  data_id,
  uparea_id,
  DATE_FORMAT(FROM_UNIXTIME(capture_time / 1000), 'yyyy-MM-dd') as capture_day,
  DATE_FORMAT(FROM_UNIXTIME(capture_time / 1000), 'HH') as capture_hour
from v64_deye_dw_ods.ods_nf_flux
where insert_day = DATE_FORMAT(FROM_UNIXTIME(UNIX_TIMESTAMP()-24 * 3600), 'yyyy-MM-dd');

