"""
ODSã€DWDå’ŒADSä¸‰æ–¹ä¸€è‡´æ€§ç»Ÿè®¡å¹¶å‘ç‰ˆæœ¬
æ”¯æŒå¤šçº¿ç¨‹å¹¶å‘æ‰§è¡Œï¼Œæé«˜ç»Ÿè®¡æ•ˆç‡
"""
import yaml
import logging
import os
import csv
import concurrent.futures
import threading
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
import sys

from hive_client import HiveClient
from ods_client import ODSClient
from es_client import ESClient


class ComparisonResult:
    """æ¯”è¾ƒç»“æœæ•°æ®ç±»"""
    def __init__(self, protocol: str, query_date: str):
        self.protocol = protocol
        self.query_date = query_date
        self.ods_total = None
        self.dwd_total = None
        self.ads_total = None
        self.ods_dwd_diff = None
        self.ods_ads_diff = None
        self.dwd_ads_diff = None
        self.ods_dwd_consistency_rate = None
        self.ods_ads_consistency_rate = None
        self.dwd_ads_consistency_rate = None
        self.status = 'FAILED'
        self.error = None
        self.duration = 0.0


class DataQualityMonitorODSConcurrent:
    """ODSã€DWDã€ADSä¸‰æ–¹æ•°æ®è´¨é‡å¹¶å‘ç›‘æ§å™¨"""
    
    def __init__(self, config_path: str = "config.yaml", max_workers: int = 5):
        """
        åˆå§‹åŒ–å¹¶å‘ç›‘æ§å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            max_workers: æœ€å¤§å¹¶å‘æ•°
        """
        self.config = self._load_config(config_path)
        self._setup_logging()
        self.max_workers = max_workers
        self.results = []
        self.results_lock = threading.Lock()
        self.logger = logging.getLogger(__name__)
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            return config
        except Exception as e:
            print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            sys.exit(1)
    
    def _setup_logging(self) -> None:
        """è®¾ç½®æ—¥å¿—"""
        log_dir = self.config['output']['log_directory']
        os.makedirs(log_dir, exist_ok=True)
        
        log_file = os.path.join(log_dir, f"ods_dwd_ads_concurrent_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
    
    def _get_query_date(self) -> str:
        """è·å–æŸ¥è¯¢æ—¥æœŸ"""
        date_config = self.config.get('date', {})
        default_date = date_config.get('default_query_date', 'yesterday')
        
        if default_date == 'yesterday':
            query_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        else:
            query_date = default_date
        
        return query_date
    
    def _format_index_pattern(self, pattern: str, query_date: str) -> str:
        """æ ¼å¼åŒ–ESç´¢å¼•æ¨¡å¼"""
        date_obj = datetime.strptime(query_date, '%Y-%m-%d')
        return pattern.format(
            year=date_obj.year,
            month=date_obj.month
        )
    
    def _compare_single_protocol(self, protocol_name: str, protocol_config: Dict[str, str], 
                               query_date: str) -> ComparisonResult:
        """
        æ¯”è¾ƒå•ä¸ªåè®®çš„ä¸‰æ–¹æ•°æ®ï¼ˆçº¿ç¨‹å®‰å…¨ç‰ˆæœ¬ï¼‰
        
        Args:
            protocol_name: åè®®åç§°
            protocol_config: åè®®é…ç½®
            query_date: æŸ¥è¯¢æ—¥æœŸ
            
        Returns:
            æ¯”è¾ƒç»“æœå¯¹è±¡
        """
        start_time = datetime.now()
        result = ComparisonResult(protocol_name, query_date)
        
        try:
            self.logger.info(f"[çº¿ç¨‹] å¼€å§‹å¤„ç†åè®®: {protocol_name}")
            
            # 1. æŸ¥è¯¢ODSæ•°æ®
            if 'ods_table' in protocol_config:
                ods_config = self.config['hive_ods']
                with ODSClient(
                    host=ods_config['host'],
                    port=ods_config['port'],
                    username=ods_config.get('username'),
                    password=ods_config.get('password'),
                    database=ods_config['database'],
                    auth=ods_config.get('auth', 'PLAIN')
                ) as ods_client:
                    result.ods_total = ods_client.get_ods_metrics(
                        table_name=protocol_config['ods_table'],
                        query_date=query_date,
                        date_field=protocol_config.get('date_field', 'capture_day')
                    )
            
            # 2. æŸ¥è¯¢DWDæ•°æ®
            if 'dwd_table' in protocol_config:
                dwd_config = self.config['hive_dwd']
                with HiveClient(
                    host=dwd_config['host'],
                    port=dwd_config['port'],
                    username=dwd_config.get('username'),
                    password=dwd_config.get('password'),
                    database=dwd_config['database'],
                    auth=dwd_config.get('auth', 'PLAIN')
                ) as dwd_client:
                    result.dwd_total = dwd_client.get_hive_metrics(
                        table_name=protocol_config['dwd_table'],
                        query_date=query_date,
                        date_field=protocol_config.get('date_field', 'capture_day')
                    )
            
            # 3. æŸ¥è¯¢ADSæ•°æ® (ES)
            if 'es_index_pattern' in protocol_config:
                es_config = self.config['elasticsearch']
                with ESClient(
                    host=es_config['host'],
                    port=es_config['port'],
                    timeout=es_config.get('timeout', 30)
                ) as es_client:
                    index_pattern = self._format_index_pattern(
                        protocol_config['es_index_pattern'], 
                        query_date
                    )
                    result.ads_total = es_client.get_es_metrics(
                        index_pattern=index_pattern,
                        query_date=query_date,
                        date_field=protocol_config['es_date_field']
                    )
            
            # 4. è®¡ç®—ä¸€è‡´æ€§æŒ‡æ ‡
            self._calculate_consistency_metrics(result)
            
            result.status = 'SUCCESS'
            
        except Exception as e:
            self.logger.error(f"[çº¿ç¨‹] å¤„ç†åè®® {protocol_name} å¤±è´¥: {e}")
            result.error = str(e)
        
        finally:
            result.duration = (datetime.now() - start_time).total_seconds()
            
            # çº¿ç¨‹å®‰å…¨åœ°æ·»åŠ ç»“æœå’Œæ‰“å°
            with self.results_lock:
                self.results.append(result)
                self._print_protocol_result(result)
        
        return result
    
    def _calculate_consistency_metrics(self, result: ComparisonResult) -> None:
        """è®¡ç®—ä¸€è‡´æ€§æŒ‡æ ‡"""
        # ODS vs DWD
        if result.ods_total is not None and result.dwd_total is not None:
            result.ods_dwd_diff = result.ods_total - result.dwd_total
            if max(result.ods_total, result.dwd_total) > 0:
                result.ods_dwd_consistency_rate = min(result.ods_total, result.dwd_total) / max(result.ods_total, result.dwd_total) * 100
            else:
                result.ods_dwd_consistency_rate = 100.0
        
        # ODS vs ADS
        if result.ods_total is not None and result.ads_total is not None:
            result.ods_ads_diff = result.ods_total - result.ads_total
            if max(result.ods_total, result.ads_total) > 0:
                result.ods_ads_consistency_rate = min(result.ods_total, result.ads_total) / max(result.ods_total, result.ads_total) * 100
            else:
                result.ods_ads_consistency_rate = 100.0
        
        # DWD vs ADS
        if result.dwd_total is not None and result.ads_total is not None:
            result.dwd_ads_diff = result.dwd_total - result.ads_total
            if max(result.dwd_total, result.ads_total) > 0:
                result.dwd_ads_consistency_rate = min(result.dwd_total, result.ads_total) / max(result.dwd_total, result.ads_total) * 100
            else:
                result.dwd_ads_consistency_rate = 100.0
    
    def _print_protocol_result(self, result: ComparisonResult) -> None:
        """æ‰“å°å•ä¸ªåè®®çš„æ¯”è¾ƒç»“æœï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        protocol = result.protocol
        status = result.status
        
        print(f"\nâœ… åè®®: {protocol} | çŠ¶æ€: {status} | è€—æ—¶: {result.duration:.1f}s")
        
        if status == 'SUCCESS':
            print(f"   ğŸ“Š ODS: {result.ods_total or 'N/A':,} | DWD: {result.dwd_total or 'N/A':,} | ADS: {result.ads_total or 'N/A':,}")
            
            if result.ods_dwd_consistency_rate is not None:
                print(f"   ğŸ”„ ODS-DWDä¸€è‡´æ€§: {result.ods_dwd_consistency_rate:.2f}%")
            if result.ods_ads_consistency_rate is not None:
                print(f"   ğŸ”„ ODS-ADSä¸€è‡´æ€§: {result.ods_ads_consistency_rate:.2f}%")
            if result.dwd_ads_consistency_rate is not None:
                print(f"   ğŸ”„ DWD-ADSä¸€è‡´æ€§: {result.dwd_ads_consistency_rate:.2f}%")
        else:
            print(f"   âŒ é”™è¯¯: {result.error}")

    def run_comparison(self) -> None:
        """è¿è¡Œå¹¶å‘ä¸‰æ–¹æ•°æ®ä¸€è‡´æ€§æ¯”è¾ƒ"""
        self.logger.info("å¼€å§‹æ‰§è¡Œå¹¶å‘ODSã€DWDå’ŒADSä¸‰æ–¹æ•°æ®ä¸€è‡´æ€§æ¯”è¾ƒ")

        query_date = self._get_query_date()
        self.logger.info(f"æŸ¥è¯¢æ—¥æœŸ: {query_date}")
        self.logger.info(f"å¹¶å‘æ•°: {self.max_workers}")

        protocols = self.config['protocols']
        total_protocols = len(protocols)

        print(f"\nğŸš€ å¼€å§‹å¹¶å‘ä¸‰æ–¹æ•°æ®ä¸€è‡´æ€§ç»Ÿè®¡ {total_protocols} ä¸ªåè®® (å¹¶å‘æ•°: {self.max_workers})")
        print("="*80)

        start_time = datetime.now()

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æ‰§è¡Œ
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_protocol = {
                executor.submit(self._compare_single_protocol, protocol_name, protocol_config, query_date): protocol_name
                for protocol_name, protocol_config in protocols.items()
            }

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            concurrent.futures.wait(future_to_protocol.keys())

        total_duration = (datetime.now() - start_time).total_seconds()

        print(f"\nğŸ‰ æ‰€æœ‰åè®®ç»Ÿè®¡å®Œæˆï¼æ€»è€—æ—¶: {total_duration:.1f}ç§’")
        self.logger.info(f"å¹¶å‘ä¸‰æ–¹æ•°æ®ä¸€è‡´æ€§æ¯”è¾ƒå®Œæˆï¼Œæ€»è€—æ—¶: {total_duration:.1f}ç§’")

    def save_results(self) -> None:
        """ä¿å­˜æ¯”è¾ƒç»“æœåˆ°CSVæ–‡ä»¶"""
        if not self.results:
            self.logger.warning("æ²¡æœ‰ç»“æœéœ€è¦ä¿å­˜")
            return

        # æŒ‰åè®®åæ’åº
        self.results.sort(key=lambda x: x.protocol)

        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = self.config['output']['csv_directory']
        os.makedirs(output_dir, exist_ok=True)

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        csv_file = os.path.join(output_dir, f"ods_dwd_ads_consistency_concurrent_{timestamp}.csv")

        # å†™å…¥CSVæ–‡ä»¶
        fieldnames = [
            'protocol', 'query_date',
            'ods_total', 'dwd_total', 'ads_total',
            'ods_dwd_diff', 'ods_ads_diff', 'dwd_ads_diff',
            'ods_dwd_consistency_rate', 'ods_ads_consistency_rate', 'dwd_ads_consistency_rate',
            'status', 'duration', 'error'
        ]

        try:
            with open(csv_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()

                for result in self.results:
                    # è½¬æ¢ç»“æœå¯¹è±¡ä¸ºå­—å…¸
                    row = {
                        'protocol': result.protocol,
                        'query_date': result.query_date,
                        'ods_total': result.ods_total if result.ods_total is not None else '',
                        'dwd_total': result.dwd_total if result.dwd_total is not None else '',
                        'ads_total': result.ads_total if result.ads_total is not None else '',
                        'ods_dwd_diff': result.ods_dwd_diff if result.ods_dwd_diff is not None else '',
                        'ods_ads_diff': result.ods_ads_diff if result.ods_ads_diff is not None else '',
                        'dwd_ads_diff': result.dwd_ads_diff if result.dwd_ads_diff is not None else '',
                        'ods_dwd_consistency_rate': result.ods_dwd_consistency_rate if result.ods_dwd_consistency_rate is not None else '',
                        'ods_ads_consistency_rate': result.ods_ads_consistency_rate if result.ods_ads_consistency_rate is not None else '',
                        'dwd_ads_consistency_rate': result.dwd_ads_consistency_rate if result.dwd_ads_consistency_rate is not None else '',
                        'status': result.status,
                        'duration': f"{result.duration:.2f}",
                        'error': result.error if result.error else ''
                    }
                    writer.writerow(row)

            self.logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {csv_file}")
            print(f"\nğŸ“„ ç»“æœå·²ä¿å­˜åˆ°: {csv_file}")

        except Exception as e:
            self.logger.error(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

    def print_summary(self) -> None:
        """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
        if not self.results:
            return

        total_protocols = len(self.results)
        success_count = sum(1 for r in self.results if r.status == 'SUCCESS')
        failed_count = total_protocols - success_count

        # è®¡ç®—å¹³å‡è€—æ—¶
        avg_duration = sum(r.duration for r in self.results) / total_protocols if total_protocols > 0 else 0

        print(f"\nğŸ“Š ç»Ÿè®¡æ‘˜è¦")
        print("="*50)
        print(f"æ€»åè®®æ•°: {total_protocols}")
        print(f"æˆåŠŸ: {success_count}")
        print(f"å¤±è´¥: {failed_count}")
        print(f"æˆåŠŸç‡: {success_count/total_protocols*100:.1f}%")
        print(f"å¹³å‡è€—æ—¶: {avg_duration:.2f}ç§’")

        if failed_count > 0:
            print(f"\nâŒ å¤±è´¥çš„åè®®:")
            for result in self.results:
                if result.status != 'SUCCESS':
                    print(f"  - {result.protocol}: {result.error or 'æœªçŸ¥é”™è¯¯'}")


def main():
    """ä¸»å‡½æ•°"""
    try:
        # å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°è°ƒæ•´å¹¶å‘æ•°
        max_workers = 5
        if len(sys.argv) > 1:
            try:
                max_workers = int(sys.argv[1])
                max_workers = max(1, min(max_workers, 20))  # é™åˆ¶åœ¨1-20ä¹‹é—´
            except ValueError:
                print("âš ï¸  å¹¶å‘æ•°å‚æ•°æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼5")

        monitor = DataQualityMonitorODSConcurrent(max_workers=max_workers)
        monitor.run_comparison()
        monitor.save_results()
        monitor.print_summary()

    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        logging.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    main()
