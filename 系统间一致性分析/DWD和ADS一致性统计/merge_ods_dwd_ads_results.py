#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°†DWDå’ŒADSçš„æ•°æ®ç»“æœè¡¥å……åˆ°ODSçš„CSVæ–‡ä»¶ä¸­
"""

import csv
import os
import glob
from datetime import datetime
from typing import Dict, List, Optional

def find_latest_csv_file(pattern: str) -> Optional[str]:
    """æŸ¥æ‰¾æœ€æ–°çš„CSVæ–‡ä»¶"""
    files = glob.glob(pattern)
    if not files:
        return None
    return max(files, key=os.path.getctime)

def read_dwd_ads_results(csv_file: str) -> Dict[str, Dict]:
    """è¯»å–DWDå’ŒADSçš„ç»“æœæ•°æ®"""
    results = {}
    
    with open(csv_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            protocol = row['protocol']
            results[protocol] = {
                'dwd_total': row['hive_total'],
                'ads_total': row['es_total'],
                'dwd_ads_diff': row['total_diff'],
                'dwd_ads_consistency_rate': row['consistency_rate'],
                'dwd_ads_status': row['status'],
                'dwd_ads_duration': row['duration'],
                'dwd_ads_error': row['error']
            }
    
    return results

def create_merged_csv(ods_csv_file: str, dwd_ads_results: Dict[str, Dict], output_file: str):
    """åˆ›å»ºåˆå¹¶åçš„CSVæ–‡ä»¶"""
    
    # å®šä¹‰æ–°çš„å­—æ®µå
    fieldnames = [
        'protocol', 'query_date',
        'ods_total', 'dwd_total', 'ads_total',
        'ods_dwd_diff', 'ods_ads_diff', 'dwd_ads_diff',
        'ods_dwd_consistency_rate', 'ods_ads_consistency_rate', 'dwd_ads_consistency_rate',
        'ods_dwd_status', 'ods_ads_status', 'dwd_ads_status',
        'ods_duration', 'dwd_ads_duration',
        'ods_error', 'dwd_ads_error'
    ]
    
    merged_data = []
    
    # å¦‚æœODSæ–‡ä»¶å­˜åœ¨ï¼Œè¯»å–ODSæ•°æ®
    if os.path.exists(ods_csv_file):
        with open(ods_csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                protocol = row['protocol']
                
                # åˆ›å»ºåˆå¹¶åçš„è¡Œæ•°æ®
                merged_row = {
                    'protocol': protocol,
                    'query_date': row['query_date'],
                    'ods_total': row.get('ods_total', ''),
                    'dwd_total': '',
                    'ads_total': '',
                    'ods_dwd_diff': row.get('ods_dwd_diff', ''),
                    'ods_ads_diff': row.get('ods_ads_diff', ''),
                    'dwd_ads_diff': '',
                    'ods_dwd_consistency_rate': row.get('ods_dwd_consistency_rate', ''),
                    'ods_ads_consistency_rate': row.get('ods_ads_consistency_rate', ''),
                    'dwd_ads_consistency_rate': '',
                    'ods_dwd_status': row.get('ods_dwd_status', ''),
                    'ods_ads_status': row.get('ods_ads_status', ''),
                    'dwd_ads_status': '',
                    'ods_duration': row.get('duration', ''),
                    'dwd_ads_duration': '',
                    'ods_error': row.get('error', ''),
                    'dwd_ads_error': ''
                }
                
                # å¦‚æœæœ‰å¯¹åº”çš„DWDå’ŒADSæ•°æ®ï¼Œè¡¥å……è¿›å»
                if protocol in dwd_ads_results:
                    dwd_ads_data = dwd_ads_results[protocol]
                    merged_row.update({
                        'dwd_total': dwd_ads_data['dwd_total'],
                        'ads_total': dwd_ads_data['ads_total'],
                        'dwd_ads_diff': dwd_ads_data['dwd_ads_diff'],
                        'dwd_ads_consistency_rate': dwd_ads_data['dwd_ads_consistency_rate'],
                        'dwd_ads_status': dwd_ads_data['dwd_ads_status'],
                        'dwd_ads_duration': dwd_ads_data['dwd_ads_duration'],
                        'dwd_ads_error': dwd_ads_data['dwd_ads_error']
                    })
                
                merged_data.append(merged_row)
    
    # æ·»åŠ åªåœ¨DWDå’ŒADSä¸­å­˜åœ¨ä½†ä¸åœ¨ODSä¸­çš„åè®®
    if os.path.exists(ods_csv_file):
        existing_protocols = {row['protocol'] for row in merged_data}
    else:
        existing_protocols = set()
    
    for protocol, dwd_ads_data in dwd_ads_results.items():
        if protocol not in existing_protocols:
            merged_row = {
                'protocol': protocol,
                'query_date': '2025-08-09',  # ä»DWDå’ŒADSæ•°æ®ä¸­è·å–
                'ods_total': '',
                'dwd_total': dwd_ads_data['dwd_total'],
                'ads_total': dwd_ads_data['ads_total'],
                'ods_dwd_diff': '',
                'ods_ads_diff': '',
                'dwd_ads_diff': dwd_ads_data['dwd_ads_diff'],
                'ods_dwd_consistency_rate': '',
                'ods_ads_consistency_rate': '',
                'dwd_ads_consistency_rate': dwd_ads_data['dwd_ads_consistency_rate'],
                'ods_dwd_status': '',
                'ods_ads_status': '',
                'dwd_ads_status': dwd_ads_data['dwd_ads_status'],
                'ods_duration': '',
                'dwd_ads_duration': dwd_ads_data['dwd_ads_duration'],
                'ods_error': '',
                'dwd_ads_error': dwd_ads_data['dwd_ads_error']
            }
            merged_data.append(merged_row)
    
    # å†™å…¥åˆå¹¶åçš„CSVæ–‡ä»¶
    with open(output_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(merged_data)
    
    return len(merged_data)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”„ å¼€å§‹åˆå¹¶ODSã€DWDå’ŒADSæ•°æ®ç»“æœ...")
    print("=" * 60)
    
    # æŸ¥æ‰¾æœ€æ–°çš„DWDå’ŒADSç»“æœæ–‡ä»¶
    dwd_ads_pattern = "output/dwd_ads_consistency_concurrent_*.csv"
    dwd_ads_file = find_latest_csv_file(dwd_ads_pattern)
    
    if not dwd_ads_file:
        print(f"âŒ æœªæ‰¾åˆ°DWDå’ŒADSç»“æœæ–‡ä»¶: {dwd_ads_pattern}")
        return
    
    print(f"ğŸ“ æ‰¾åˆ°DWDå’ŒADSç»“æœæ–‡ä»¶: {dwd_ads_file}")
    
    # æŸ¥æ‰¾æœ€æ–°çš„ODSç»“æœæ–‡ä»¶
    ods_pattern = "output/ods_dwd_ads_consistency_concurrent_*.csv"
    ods_file = find_latest_csv_file(ods_pattern)
    
    if ods_file:
        print(f"ğŸ“ æ‰¾åˆ°ODSç»“æœæ–‡ä»¶: {ods_file}")
    else:
        print("âš ï¸  æœªæ‰¾åˆ°ODSç»“æœæ–‡ä»¶ï¼Œå°†åªä½¿ç”¨DWDå’ŒADSæ•°æ®")
    
    # è¯»å–DWDå’ŒADSç»“æœ
    print("ğŸ“– è¯»å–DWDå’ŒADSæ•°æ®...")
    dwd_ads_results = read_dwd_ads_results(dwd_ads_file)
    print(f"âœ… è¯»å–åˆ° {len(dwd_ads_results)} ä¸ªåè®®çš„DWDå’ŒADSæ•°æ®")
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = f"output/merged_ods_dwd_ads_consistency_{timestamp}.csv"
    
    # åˆ›å»ºåˆå¹¶åçš„CSVæ–‡ä»¶
    print("ğŸ”„ åˆå¹¶æ•°æ®...")
    total_rows = create_merged_csv(ods_file if ods_file else "", dwd_ads_results, output_file)
    
    print(f"âœ… åˆå¹¶å®Œæˆï¼")
    print(f"ğŸ“Š æ€»å…±å¤„ç† {total_rows} ä¸ªåè®®")
    print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {output_file}")
    
    # æ˜¾ç¤ºæ–‡ä»¶å†…å®¹é¢„è§ˆ
    print(f"\nğŸ“‹ æ–‡ä»¶å†…å®¹é¢„è§ˆ:")
    print("-" * 60)
    with open(output_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
        for i, line in enumerate(lines[:6]):  # æ˜¾ç¤ºå‰5è¡Œæ•°æ®
            print(f"{i+1:2d}: {line.strip()}")
        if len(lines) > 6:
            print(f"... è¿˜æœ‰ {len(lines) - 6} è¡Œæ•°æ®")

if __name__ == "__main__":
    main()
