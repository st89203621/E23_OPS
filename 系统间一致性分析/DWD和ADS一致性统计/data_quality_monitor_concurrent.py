"""
DWDå’ŒADSä¸€è‡´æ€§ç»Ÿè®¡ä¸»ç¨‹åº - å¹¶å‘ç‰ˆæœ¬ï¼ˆä»…æ€»æ•°ç»Ÿè®¡ï¼‰
"""
import yaml
import logging
import os
import csv
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
import sys
import concurrent.futures
import threading
from dataclasses import dataclass

from hive_client import HiveClient
from es_client import ESClient


@dataclass
class ProtocolResult:
    """åè®®ç»Ÿè®¡ç»“æœ"""
    protocol: str
    query_date: str
    hive_total: Optional[int] = None
    es_total: Optional[int] = None
    total_diff: Optional[int] = None
    consistency_rate: Optional[float] = None
    status: str = 'PENDING'
    error: Optional[str] = None
    duration: Optional[float] = None


class ConcurrentDataQualityMonitor:
    """å¹¶å‘æ•°æ®è´¨é‡ç›‘æ§å™¨"""
    
    def __init__(self, config_path: str = "config.yaml", max_workers: int = 8):
        """
        åˆå§‹åŒ–ç›‘æ§å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            max_workers: æœ€å¤§å¹¶å‘æ•°
        """
        self.config = self._load_config(config_path)
        self.max_workers = max_workers
        self._setup_logging()
        self.results: List[ProtocolResult] = []
        self.lock = threading.Lock()
        
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            return config
        except Exception as e:
            print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            sys.exit(1)
    
    def _setup_logging(self) -> None:
        """è®¾ç½®æ—¥å¿—"""
        log_dir = self.config['output']['log_directory']
        os.makedirs(log_dir, exist_ok=True)
        
        log_file = os.path.join(log_dir, f"data_quality_concurrent_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        
        self.logger = logging.getLogger(__name__)
        self.logger.info("å¹¶å‘æ•°æ®è´¨é‡ç›‘æ§å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _get_query_date(self) -> str:
        """è·å–æŸ¥è¯¢æ—¥æœŸ"""
        date_config = self.config.get('date', {})
        default_date = date_config.get('default_query_date', 'yesterday')
        
        if default_date == 'yesterday':
            return (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        else:
            return default_date
    
    def _format_index_pattern(self, pattern: str, query_date: str) -> str:
        """æ ¼å¼åŒ–ESç´¢å¼•æ¨¡å¼"""
        date_obj = datetime.strptime(query_date, '%Y-%m-%d')
        return pattern.format(
            year=date_obj.year,
            month=date_obj.month
        )
    
    def _compare_single_protocol(self, protocol_name: str, protocol_config: Dict[str, Any], query_date: str) -> ProtocolResult:
        """æ¯”è¾ƒå•ä¸ªåè®®çš„æ•°æ®ï¼ˆä»…æ€»æ•°ï¼‰"""
        start_time = datetime.now()
        result = ProtocolResult(
            protocol=protocol_name,
            query_date=query_date
        )
        
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†åè®®: {protocol_name}")
            
            # æŸ¥è¯¢Hiveæ•°æ®
            hive_config = self.config['hive']
            with HiveClient(
                host=hive_config['host'],
                port=hive_config['port'],
                username=hive_config.get('username'),
                password=hive_config.get('password'),
                database=hive_config['database'],
                auth=hive_config.get('auth', 'PLAIN')
            ) as hive_client:
                
                hive_total = hive_client.get_hive_metrics(
                    table_name=protocol_config['hive_table'],
                    query_date=query_date
                )
                result.hive_total = hive_total
            
            # æŸ¥è¯¢ESæ•°æ®
            es_config = self.config['elasticsearch']
            with ESClient(
                host=es_config['host'],
                port=es_config['port'],
                timeout=es_config.get('timeout', 30)
            ) as es_client:
                
                index_pattern = self._format_index_pattern(
                    protocol_config['es_index_pattern'], 
                    query_date
                )
                
                es_total = es_client.get_es_metrics(
                    index_pattern=index_pattern,
                    query_date=query_date,
                    date_field=protocol_config['es_date_field']
                )
                result.es_total = es_total
            
            # è®¡ç®—å·®å¼‚å’Œä¸€è‡´æ€§ç‡
            if hive_total is not None and es_total is not None:
                result.total_diff = hive_total - es_total
                if max(hive_total, es_total) > 0:
                    result.consistency_rate = min(hive_total, es_total) / max(hive_total, es_total) * 100
                else:
                    result.consistency_rate = 100.0
                
                # åˆ¤æ–­çŠ¶æ€
                if result.consistency_rate >= 99.0:
                    result.status = 'GOOD'
                elif result.consistency_rate >= 95.0:
                    result.status = 'WARNING'
                else:
                    result.status = 'ERROR'
            else:
                result.status = 'FAILED'
            
            # è®¡ç®—è€—æ—¶
            result.duration = (datetime.now() - start_time).total_seconds()
            
            self.logger.info(f"åè®® {protocol_name} å¤„ç†å®Œæˆ - çŠ¶æ€: {result.status}, è€—æ—¶: {result.duration:.1f}s")
            
        except Exception as e:
            result.status = 'FAILED'
            result.error = str(e)
            result.duration = (datetime.now() - start_time).total_seconds()
            self.logger.error(f"å¤„ç†åè®® {protocol_name} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        
        # çº¿ç¨‹å®‰å…¨åœ°æ·»åŠ ç»“æœå¹¶æ‰“å°
        with self.lock:
            self.results.append(result)
            self._print_protocol_result(result, len(self.results))
        
        return result
    
    def _print_protocol_result(self, result: ProtocolResult, current: int) -> None:
        """æ‰“å°å•ä¸ªåè®®çš„ç»“æœ"""
        status_color = {
            'GOOD': '\033[92m',      # ç»¿è‰²
            'WARNING': '\033[93m',   # é»„è‰²
            'ERROR': '\033[91m',     # çº¢è‰²
            'FAILED': '\033[91m'     # çº¢è‰²
        }
        reset_color = '\033[0m'
        
        color = status_color.get(result.status, '')
        
        print(f"\n[{current}/29] {color}{result.protocol.upper()}{reset_color} - {color}{result.status}{reset_color} ({result.duration:.1f}s)")
        
        if result.hive_total is not None and result.es_total is not None:
            print(f"  Hive: {result.hive_total:,}")
            print(f"  ES:   {result.es_total:,}")
            print(f"  å·®å¼‚: {result.total_diff:,}")
            print(f"  ä¸€è‡´æ€§: {result.consistency_rate:.1f}%")
        else:
            print(f"  Hive: {result.hive_total}")
            print(f"  ES:   {result.es_total}")
        
        if result.error:
            print(f"  é”™è¯¯: {result.error}")
    
    def run_comparison(self) -> None:
        """è¿è¡Œå¹¶å‘æ•°æ®ä¸€è‡´æ€§æ¯”è¾ƒ"""
        self.logger.info("å¼€å§‹æ‰§è¡Œå¹¶å‘DWDå’ŒADSæ•°æ®ä¸€è‡´æ€§æ¯”è¾ƒ")
        
        query_date = self._get_query_date()
        self.logger.info(f"æŸ¥è¯¢æ—¥æœŸ: {query_date}")
        self.logger.info(f"å¹¶å‘æ•°: {self.max_workers}")
        
        protocols = self.config['protocols']
        total_protocols = len(protocols)
        
        print(f"\nğŸš€ å¼€å§‹å¹¶å‘ç»Ÿè®¡ {total_protocols} ä¸ªåè®® (å¹¶å‘æ•°: {self.max_workers})")
        print("="*80)
        
        start_time = datetime.now()
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æ‰§è¡Œ
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_protocol = {
                executor.submit(self._compare_single_protocol, protocol_name, protocol_config, query_date): protocol_name
                for protocol_name, protocol_config in protocols.items()
            }
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            concurrent.futures.wait(future_to_protocol.keys())
        
        total_duration = (datetime.now() - start_time).total_seconds()
        
        print(f"\nğŸ‰ æ‰€æœ‰åè®®ç»Ÿè®¡å®Œæˆï¼æ€»è€—æ—¶: {total_duration:.1f}ç§’")
        self.logger.info(f"å¹¶å‘æ•°æ®ä¸€è‡´æ€§æ¯”è¾ƒå®Œæˆï¼Œæ€»è€—æ—¶: {total_duration:.1f}ç§’")
    
    def save_results(self) -> None:
        """ä¿å­˜æ¯”è¾ƒç»“æœåˆ°CSVæ–‡ä»¶"""
        if not self.results:
            self.logger.warning("æ²¡æœ‰ç»“æœéœ€è¦ä¿å­˜")
            return
        
        # æŒ‰åè®®åæ’åº
        self.results.sort(key=lambda x: x.protocol)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = self.config['output']['csv_directory']
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        csv_file = os.path.join(output_dir, f"dwd_ads_consistency_concurrent_{timestamp}.csv")
        
        # å†™å…¥CSVæ–‡ä»¶
        fieldnames = [
            'protocol', 'query_date', 'hive_total', 'es_total', 
            'total_diff', 'consistency_rate', 'status', 'duration', 'error'
        ]
        
        try:
            with open(csv_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                
                for result in self.results:
                    writer.writerow({
                        'protocol': result.protocol,
                        'query_date': result.query_date,
                        'hive_total': result.hive_total,
                        'es_total': result.es_total,
                        'total_diff': result.total_diff,
                        'consistency_rate': result.consistency_rate,
                        'status': result.status,
                        'duration': result.duration,
                        'error': result.error
                    })
            
            self.logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {csv_file}")
            
            # æ‰“å°æ‘˜è¦
            self._print_summary()
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
    
    def _print_summary(self) -> None:
        """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
        if not self.results:
            return
        
        total_count = len(self.results)
        good_count = sum(1 for r in self.results if r.status == 'GOOD')
        warning_count = sum(1 for r in self.results if r.status == 'WARNING')
        error_count = sum(1 for r in self.results if r.status == 'ERROR')
        failed_count = sum(1 for r in self.results if r.status == 'FAILED')
        
        avg_duration = sum(r.duration for r in self.results if r.duration) / total_count
        
        print("\n" + "="*80)
        print("ğŸ“Š æ•°æ®ä¸€è‡´æ€§ç»Ÿè®¡æ‘˜è¦")
        print("="*80)
        print(f"æ€»åè®®æ•°: {total_count}")
        print(f"ğŸŸ¢ è‰¯å¥½ (GOOD): {good_count} ({good_count/total_count*100:.1f}%)")
        print(f"ğŸŸ¡ è­¦å‘Š (WARNING): {warning_count} ({warning_count/total_count*100:.1f}%)")
        print(f"ğŸ”´ é”™è¯¯ (ERROR): {error_count} ({error_count/total_count*100:.1f}%)")
        print(f"âŒ å¤±è´¥ (FAILED): {failed_count} ({failed_count/total_count*100:.1f}%)")
        print(f"â±ï¸  å¹³å‡è€—æ—¶: {avg_duration:.1f}ç§’/åè®®")
        print("="*80)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='DWDå’ŒADSæ•°æ®ä¸€è‡´æ€§å¹¶å‘ç»Ÿè®¡')
    parser.add_argument('--workers', type=int, default=8, help='å¹¶å‘çº¿ç¨‹æ•° (é»˜è®¤: 8)')
    args = parser.parse_args()
    
    monitor = ConcurrentDataQualityMonitor(max_workers=args.workers)
    monitor.run_comparison()
    monitor.save_results()


if __name__ == "__main__":
    main()
